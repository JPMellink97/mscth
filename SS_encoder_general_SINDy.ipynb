{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysindy as ps\n",
    "\n",
    "import deepSI\n",
    "from deepSI.fit_systems import SS_encoder_general\n",
    "from deepSI.fit_systems.encoders import default_encoder_net, default_state_net, default_output_net\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "import deepSI\n",
    "from deepSI import System_data\n",
    "\n",
    "from utils import load_data, normalize\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000,), (1000, 2), (1000, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data, u_data, y_data, th_data = load_data(pc=0)\n",
    "\n",
    "train, test = System_data(u=u_data[:10000,0],y=x_data[:10000,:]), System_data(u=u_data[-1000:],y=x_data[-1000:,:])\n",
    "\n",
    "train.y.shape, train.u.shape, test.y.shape, test.u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SS_encoder_general_eq(SS_encoder_general):\n",
    "    def __init__(self, nx=10, na=20, nb=20, feedthrough=False, \\\n",
    "        e_net=default_encoder_net, f_net=default_state_net, h_net=default_output_net, \\\n",
    "        e_net_kwargs={},           f_net_kwargs={},         h_net_kwargs={}, na_right=0, nb_right=0, \\\n",
    "        gamma=1e-4):\n",
    "\n",
    "        super(SS_encoder_general_eq, self).__init__()\n",
    "        self.nx, self.na, self.nb = nx, na, nb\n",
    "        self.k0 = max(self.na,self.nb)\n",
    "        \n",
    "        self.e_net = e_net\n",
    "        self.e_net_kwargs = e_net_kwargs\n",
    "\n",
    "        self.f_net = f_net\n",
    "        self.f_net_kwargs = f_net_kwargs\n",
    "\n",
    "        self.h_net = h_net\n",
    "        self.h_net_kwargs = h_net_kwargs\n",
    "\n",
    "        self.feedthrough = feedthrough\n",
    "        self.na_right = na_right\n",
    "        self.nb_right = nb_right\n",
    "        ######################################\n",
    "        # args added for feature transform and\n",
    "        # regurlarization\n",
    "        self.gamma = gamma\n",
    "        ######################################\n",
    "\n",
    "    def init_nets(self, nu, ny): # a bit weird\n",
    "        na_right = self.na_right if hasattr(self,'na_right') else 0\n",
    "        nb_right = self.nb_right if hasattr(self,'nb_right') else 0\n",
    "        self.encoder = self.e_net(nb=(self.nb+nb_right), nu=nu, na=(self.na+na_right), ny=ny, nx=self.nx, **self.e_net_kwargs)\n",
    "        ######################################\n",
    "        ###### change fn intialization #######\n",
    "        self.fn     =      self.f_net(nx=self.nx, nu=nu, **self.f_net_kwargs)\n",
    "        ######################################\n",
    "        if self.feedthrough:\n",
    "            self.hn =      self.h_net(nx=self.nx, ny=ny, nu=nu,                     **self.h_net_kwargs) \n",
    "        else:\n",
    "            self.hn =      self.h_net(nx=self.nx, ny=ny,                            **self.h_net_kwargs) \n",
    "\n",
    "    def loss(self, uhist, yhist, ufuture, yfuture, loss_nf_cutoff=None, **Loss_kwargs):\n",
    "        x = self.encoder(uhist, yhist) #initialize Nbatch number of states\n",
    "        errors = []\n",
    "        for y, u in zip(torch.transpose(yfuture,0,1), torch.transpose(ufuture,0,1)): #iterate over time\n",
    "            error = nn.functional.mse_loss(y, self.hn(x,u) if self.feedthrough else self.hn(x))\n",
    "            ##################################\n",
    "            ## add penalty to weights in fn ##\n",
    "            # params = [*self.fn.parameters()]\n",
    "            # weights = [x.view(-1) for x in params][0]\n",
    "            # error += self.gamma*torch.norm(weights, 1)\n",
    "            ##################################\n",
    "            errors.append(error) #calculate error after taking n-steps\n",
    "            if loss_nf_cutoff is not None and error.item()>loss_nf_cutoff:\n",
    "                print(len(errors), end=' ')\n",
    "                break\n",
    "            x = self.fn(x,u) #advance state.\n",
    "        \n",
    "            \n",
    "        return torch.mean(torch.stack(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class h_identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "    \n",
    "class e_identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        output = input[-1]\n",
    "        output = torch.reshape(output,(output.shape[0], output.shape[-1]))\n",
    "    \n",
    "        return output\n",
    "    \n",
    "class simple_Linear(torch.nn.Module):\n",
    "    def __init__(self, nx, nu, **kwargs):\n",
    "        super(simple_Linear, self).__init__()\n",
    "\n",
    "        self.nx = nx\n",
    "        self.nu = kwargs['u']\n",
    "\n",
    "        self.feature_library = kwargs['feature_library']\n",
    "        test_sample = torch.rand(1,self.nx+self.nu, requires_grad=True)\n",
    "        self.nf = (self.feature_library.fit_transform(test_sample)).shape[1]\n",
    "        \n",
    "        self.layer = nn.Linear(self.nf, nx, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x, u):\n",
    "        # make sure u is column\n",
    "        u = torch.reshape(u, (u.shape[-1],1))\n",
    "        x = torch.hstack((x, u))\n",
    "        Theta = self.feature_library.fit_transform(x)\n",
    "        out = self.layer(Theta)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_library():\n",
    "    \"\"\" Class object that holds the features for constructing the functions basis.\n",
    "\n",
    "        Attributes:\n",
    "            functions (list)        : list of function objects\n",
    "            nx (int)                : the number of states\n",
    "            nu (int)                : the number of inputs\n",
    "            include_one (bool)      : choose to include an offset\n",
    "            interaction_only (bool) : true exlcudes terms such as x1[k]*x2[k]\n",
    "\n",
    "        Methods:\n",
    "            __init__(self, functions, nx, nu, include_one, interaction_only):\n",
    "                Constructor\n",
    "\n",
    "            fit_transform(self, X):\n",
    "                Transforms data in X using the specified functions stored in self.functions\n",
    "\n",
    "            feature_names(self):\n",
    "                Returns a list of strings which correspond to the features in self.functions\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            functions,\n",
    "            nx,\n",
    "            nu,\n",
    "            include_one = True,\n",
    "            interaction_only=True\n",
    "    ):\n",
    "        self.functions = functions\n",
    "        # TODO: add interaction only to include/exclude cross terms\n",
    "        # now functions are applied to all states and inputs\n",
    "        self.interaction_only = interaction_only\n",
    "\n",
    "        # set to false to exclude possible offset\n",
    "        self.include_one = include_one\n",
    "\n",
    "        # creates list of factors that are in system\n",
    "        # x0[k],..., xn[k], u0[k],..., un[k]\n",
    "        self.term_list = [f\"x{i}[k]\" for i in range(nx)]\n",
    "        input_list = [f\"u{i}[k]\" for i in range(nu)]\n",
    "        self.term_list.extend(input_list)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # if include_one = True add term for offset\n",
    "        out_feature = ((X[:,0])**0).unsqueeze(1) if self.include_one else torch.empty(X.shape[0], 1)\n",
    "        if self.interaction_only:\n",
    "            for f in self.functions:\n",
    "                out_feature = torch.hstack((out_feature, f(X)[0]))\n",
    "            return out_feature\n",
    "        # TODO: add the stuff for cross terms\n",
    "        \n",
    "    def feature_names(self):\n",
    "        # returns list with feature names\n",
    "        flist = [\"1\"] if self.include_one else []\n",
    "        for f in self.functions:\n",
    "            for x in self.term_list:\n",
    "                flist.append(f(torch.tensor(1.),f\"{x}\")[-1])\n",
    "        return flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, name=\"_\"):\n",
    "  return x, f\"{name}\"\n",
    "\n",
    "def f2(x, name=\"_\"):\n",
    "  return x**2, f\"{name}**2\"\n",
    "\n",
    "def f3(x, name=\"_\"):\n",
    "  return x**3, f\"{name}**3\"\n",
    "\n",
    "def sin(x, name=\"_\"):\n",
    "  return torch.sin(x), f\"sin({name})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [f, sin]\n",
    "\n",
    "poly = feature_library(functions=functions, nx=2, nu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilizing the model and optimizer\n",
      "Size of the training array =  22.8 MB\n",
      "N_training_samples = 9900, batch_size = 9900, N_batch_updates_per_epoch = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation sim-NRMS= 189.75283873845834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n",
      "torch.Size([9900, 2]) torch.Size([9900, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## New lowest validation loss achieved ########### sim-NRMS = 188.28141538035192\n",
      "Epoch    1, sqrt loss  0.1773, Val sim-NRMS  188.3, Time Loss: 74.6%, data: 1.0%, val: 24.4%,  1.2 sec/batch\n",
      "Loaded model with best known validation sim-NRMS of  188.3 which happened on epoch 1 (epoch_id=1.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fit_sys = deepSI.fit_systems.SS_encoder_general(nx=2, na=50, nb=50)\n",
    "\n",
    "nx, nu = 2, 1 # state dimension and inputs\n",
    "na, nb = 1, 0\n",
    "\n",
    "f_net = simple_Linear\n",
    "f_net_kwargs = {\"feature_library\": poly, \"u\": nu, \"nf\": 7}\n",
    "\n",
    "# e_net_kwargs = {\"slot\": 1}\n",
    "\n",
    "h_net = h_identity\n",
    "h_net_kwargs = {}\n",
    "\n",
    "fit_sys = SS_encoder_general_eq(nx=nx, na=na, nb=nb, \\\n",
    "                                f_net=f_net, f_net_kwargs=f_net_kwargs,\\\n",
    "                                e_net=e_identity, e_net_kwargs=f_net_kwargs,\\\n",
    "                                h_net=h_net)\n",
    "\n",
    "\n",
    "fit_sys.fit(train, test, epochs=1, batch_size = 9900, optimizer_kwargs={\"lr\": 1e-3}, loss_kwargs=dict(nf=100), auto_fit_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27900198, -0.36201245, -0.22251362, -0.3190518 , -0.2969291 ,\n",
       "         0.34710744,  0.07655019],\n",
       "       [ 0.20583577, -0.01664452, -0.28023294, -0.27788538,  0.365198  ,\n",
       "        -0.27606222,  0.36894867]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found = [*fit_sys.fn.parameters()][0].detach().numpy()\n",
    "\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sim_enc = fit_sys.apply_experiment(test)\n",
    "\n",
    "# plt.plot(test.y)\n",
    "# plt.plot(test.y - test_sim_enc.y)\n",
    "# plt.title(f'test set simulation SS encoder, NRMS = {test_sim_enc.NRMS(test):.2%}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NRMS(y_pred, y_true):\n",
    "#     RMS = np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "#     return RMS/np.std(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test.y[:,0])\n",
    "# plt.plot(test.y[:,0]-test_sim_enc.y[:,0],'--')\n",
    "# plt.title(f'test set simulation SS encoder, NRMS = {NRMS(test_sim_enc.y[:,0],test.y[:,0]):.2%}')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(test.y[:,1])\n",
    "# plt.plot(test.y[:,1]-test_sim_enc.y[:,1],'--')\n",
    "# plt.title(f'test set simulation SS encoder, NRMS = {NRMS(test_sim_enc.y[:,1],test.y[:,1]):.2%}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(test_sim_enc.y[:,1],'--')\n",
    "# plt.plot(test.y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found = [*fit_sys.fn.parameters()][0].detach().numpy()\n",
    "# true = np.array([[0, 1, 1, 0, 0, 0, 0],[0, -0.1, 0.5, 0.1, -0.2, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1,ax2) = plt.subplots(2, 1)\n",
    "\n",
    "# x_labels = [\"1\",\"x0[k]\",\"x1[k]\",\"u[k]\",\"sin(x0[k])\",\"sin([x1[k]])\",\"sin(u[k])\"]\n",
    "\n",
    "# data1 = np.vstack((true[0,:],found[0,:]))\n",
    "# data2 = np.vstack((true[1,:],found[1,:]))\n",
    "# cmap_white = LinearSegmentedColormap.from_list(\"white\", [(1, 1, 1), (1, 1, 1)])\n",
    "\n",
    "# im = ax1.imshow(data1, cmap=cmap_white)\n",
    "\n",
    "# ax1.set_xticks(np.arange(data1.shape[1]), labels=x_labels, rotation=25)\n",
    "# ax1.set_yticks(np.arange(data1.shape[0]), labels=[\"True\", \"Found\"])\n",
    "\n",
    "# for i in range(data1.shape[0]):\n",
    "#     for j in range(data1.shape[1]):\n",
    "#         text = ax1.text(j, i, round(data1[i, j],3),\n",
    "#                        ha=\"center\", va=\"center\", color=\"k\")\n",
    "#         rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='black', linewidth=1)\n",
    "#         ax1.add_patch(rect)\n",
    "\n",
    "# ax1.patch.set_linewidth(2.0)        \n",
    "# ax1.patch.set_edgecolor('black')\n",
    "\n",
    "# # second\n",
    "# im = ax2.imshow(data2, cmap=cmap_white)\n",
    "\n",
    "# ax2.set_xticks(np.arange(data2.shape[1]), labels=x_labels, rotation=25)\n",
    "# ax2.set_yticks(np.arange(data2.shape[0]), labels=[\"True\", \"Found\"])\n",
    "\n",
    "# for i in range(data2.shape[0]):\n",
    "#     for j in range(data2.shape[1]):\n",
    "#         text = ax2.text(j, i, round(data2[i, j], 3),\n",
    "#                        ha=\"center\", va=\"center\", color=\"k\")\n",
    "#         rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='black', linewidth=1)\n",
    "#         ax2.add_patch(rect)\n",
    "\n",
    "# ax2.patch.set_linewidth(2.0)        \n",
    "# ax2.patch.set_edgecolor('black')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
