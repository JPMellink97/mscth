{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pysindy as ps\n",
    "\n",
    "import deepSI\n",
    "from deepSI.fit_systems import SS_encoder_general\n",
    "from deepSI.fit_systems.encoders import default_encoder_net, default_state_net, default_output_net\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "import deepSI\n",
    "from deepSI import System_data\n",
    "\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r\"C:\\Users\\20173928\\OneDrive - TU Eindhoven\\Documents\\Master\\thesis\\mscth\\data\\own_data\"\n",
    "\n",
    "out = loadmat(os.path.join(save_dir,'MSD_x_data.mat'))\n",
    "x_data = out['x']\n",
    "\n",
    "out = loadmat(os.path.join(save_dir,'MSD_u_data.mat'))\n",
    "u_data = out['u']\n",
    "\n",
    "out = loadmat(os.path.join(save_dir,'MSD_y_data.mat'))\n",
    "y_data = out['y']\n",
    "\n",
    "train, test = System_data(u=u_data[:-1000,0],y=y_data[:-1000,0]), System_data(u=u_data[-1000:,0],y=y_data[-1000:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000,), (1000, 2), (1000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data, u_data, y_data, th_data = load_data(pc=0)\n",
    "\n",
    "train, test = System_data(u=u_data[:10000,0],y=x_data[:10000,:]), System_data(u=u_data[-1000:],y=x_data[-1000:,:])\n",
    "\n",
    "train.y.shape, train.u.shape, test.y.shape, test.u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SS_encoder_general_eq(SS_encoder_general):\n",
    "    def __init__(self, nx=10, na=20, nb=20, feedthrough=False, \\\n",
    "        e_net=default_encoder_net, f_net=default_state_net, h_net=default_output_net, \\\n",
    "        e_net_kwargs={},           f_net_kwargs={},         h_net_kwargs={}, na_right=0, nb_right=0, \\\n",
    "        gamma=1e-4):\n",
    "\n",
    "        super(SS_encoder_general_eq, self).__init__()\n",
    "        self.nx, self.na, self.nb = nx, na, nb\n",
    "        self.k0 = max(self.na,self.nb)\n",
    "        \n",
    "        self.e_net = e_net\n",
    "        self.e_net_kwargs = e_net_kwargs\n",
    "\n",
    "        self.f_net = f_net\n",
    "        self.f_net_kwargs = f_net_kwargs\n",
    "\n",
    "        self.h_net = h_net\n",
    "        self.h_net_kwargs = h_net_kwargs\n",
    "\n",
    "        self.feedthrough = feedthrough\n",
    "        self.na_right = na_right\n",
    "        self.nb_right = nb_right\n",
    "        ######################################\n",
    "        # args added for feature transform and\n",
    "        # regurlarization\n",
    "        self.gamma = gamma\n",
    "        ######################################\n",
    "\n",
    "    def init_nets(self, nu, ny): # a bit weird\n",
    "        na_right = self.na_right if hasattr(self,'na_right') else 0\n",
    "        nb_right = self.nb_right if hasattr(self,'nb_right') else 0\n",
    "        self.encoder = self.e_net(nb=(self.nb+nb_right), nu=nu, na=(self.na+na_right), ny=ny, nx=self.nx, **self.e_net_kwargs)\n",
    "        ######################################\n",
    "        ###### change fn intialization #######\n",
    "        self.fn     =      self.f_net(nx=self.nx, nu=nu, **self.f_net_kwargs)\n",
    "        ######################################\n",
    "        if self.feedthrough:\n",
    "            self.hn =      self.h_net(nx=self.nx, ny=ny, nu=nu,                     **self.h_net_kwargs) \n",
    "        else:\n",
    "            self.hn =      self.h_net(nx=self.nx, ny=ny,                            **self.h_net_kwargs) \n",
    "\n",
    "    def loss(self, uhist, yhist, ufuture, yfuture, loss_nf_cutoff=None, **Loss_kwargs):\n",
    "        x = self.encoder(uhist, yhist) #initialize Nbatch number of states\n",
    "        # print(torch.max(x))\n",
    "        # print()\n",
    "        errors = []\n",
    "        for y, u in zip(torch.transpose(yfuture,0,1), torch.transpose(ufuture,0,1)): #iterate over time\n",
    "            error = nn.functional.mse_loss(y, self.hn(x,u) if self.feedthrough else self.hn(x))\n",
    "            ##################################\n",
    "            ## add penalty to weights in fn ##\n",
    "            # params = [*self.fn.parameters()]\n",
    "            # weights = [x.view(-1) for x in params][0]\n",
    "            # error += self.gamma*torch.norm(weights, 1)\n",
    "            ##################################\n",
    "            errors.append(error) #calculate error after taking n-steps\n",
    "            if loss_nf_cutoff is not None and error.item()>loss_nf_cutoff:\n",
    "                print(len(errors), end=' ')\n",
    "                break\n",
    "            x = self.fn(x,u) #advance state. \n",
    "            \n",
    "        return torch.mean(torch.stack(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return input\n",
    "    \n",
    "class simple_Linear(torch.nn.Module):\n",
    "    def __init__(self, nx, nu, **kwargs):\n",
    "        super(simple_Linear, self).__init__()\n",
    "\n",
    "        self.nx = nx\n",
    "        self.nu = kwargs['u']\n",
    "\n",
    "        self.feature_library = kwargs['feature_library']\n",
    "        test_sample = torch.rand(1,self.nx+self.nu, requires_grad=True)\n",
    "        self.nf = (self.feature_library.fit_transform(test_sample)).shape[1]\n",
    "        \n",
    "        self.layer = nn.Linear(self.nf, nx, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x, u):\n",
    "        x = torch.hstack((x, u.unsqueeze(1)))\n",
    "        Theta = self.feature_library.fit_transform(x)\n",
    "        out = self.layer(Theta)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_library():\n",
    "    def __init__(\n",
    "            self,\n",
    "            functions,\n",
    "            interaction_only=True\n",
    "    ):\n",
    "        self.functions = functions\n",
    "        self.interaction_only = interaction_only\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # off set\n",
    "        out_feature = ((X[:,0])**0).unsqueeze(1)\n",
    "        if self.interaction_only:\n",
    "            for f in self.functions:\n",
    "                out_feature = torch.hstack((out_feature, f(X)))\n",
    "            return out_feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  return x\n",
    "\n",
    "def f2(x):\n",
    "  return x**2\n",
    "\n",
    "def sin(x):\n",
    "  return np.sin(x)\n",
    "\n",
    "def f3(x):\n",
    "  return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions = [lambda x:x,\n",
    "#              lambda x:x**2,\n",
    "#              lambda x:x**3]\n",
    "functions = [f, f3]\n",
    "\n",
    "poly = feature_library(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilizing the model and optimizer\n",
      "Size of the training array =  22.7 MB\n",
      "N_training_samples = 9901, batch_size = 2, N_batch_updates_per_epoch = 4950\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "identity.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m h_net_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     12\u001b[0m fit_sys \u001b[38;5;241m=\u001b[39m SS_encoder_general_eq(nx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, na\u001b[38;5;241m=\u001b[39mna, nb\u001b[38;5;241m=\u001b[39mnb, \\\n\u001b[0;32m     13\u001b[0m                                 f_net\u001b[38;5;241m=\u001b[39mf_net, f_net_kwargs\u001b[38;5;241m=\u001b[39mf_net_kwargs,\\\n\u001b[0;32m     14\u001b[0m                                 e_net\u001b[38;5;241m=\u001b[39midentity,\\\n\u001b[0;32m     15\u001b[0m                                 h_net\u001b[38;5;241m=\u001b[39midentity)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mfit_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\fit_systems\\fit_system.py:364\u001b[0m, in \u001b[0;36mSystem_torch.fit\u001b[1;34m(self, train_sys_data, val_sys_data, epochs, batch_size, loss_kwargs, auto_fit_norm, validation_measure, optimizer_kwargs, concurrent_val, cuda, timeout, verbose, sqrt_train, num_workers_data_loader, print_full_time_profile, scheduler_kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote_send(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m), extra_t)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#start with the initial validation \u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_t\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#also sets current model to cuda\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose: \n\u001b[0;32m    366\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Validation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_measure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoss_val[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\fit_systems\\fit_system.py:296\u001b[0m, in \u001b[0;36mSystem_torch.fit.<locals>.validation\u001b[1;34m(train_loss, time_elapsed_total)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation\u001b[39m(train_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, time_elapsed_total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(); \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m--> 296\u001b[0m     Loss_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_validation_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_sys_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_measure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_measure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoss_val\u001b[38;5;241m.\u001b[39mappend(Loss_val)\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLoss_train\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\fit_systems\\fit_system.py:220\u001b[0m, in \u001b[0;36mSystem_torch.cal_validation_error\u001b[1;34m(self, val_sys_data, validation_measure)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''possible validation_measure are\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m'sim-NRMS'\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m'sim-NRMS_mean_channel'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m'sim-inno' #todo\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_measure\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 220\u001b[0m     val_sys_data_sim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_sys_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     sim_val_fun \u001b[38;5;241m=\u001b[39m validation_measure\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sim_val_fun\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNRMS_sys_norm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\systems\\system.py:151\u001b[0m, in \u001b[0;36mSystem.apply_experiment\u001b[1;34m(self, sys_data, save_state, init_state)\u001b[0m\n\u001b[0;32m    149\u001b[0m     k0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys_data_norm\u001b[38;5;241m.\u001b[39my \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     k0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys_data_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     Y\u001b[38;5;241m.\u001b[39mextend(sys_data_norm\u001b[38;5;241m.\u001b[39my[:k0])\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\systems\\system.py:234\u001b[0m, in \u001b[0;36mSystem.init_state\u001b[1;34m(self, sys_data)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_state_multi\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit_state_and_measure_multi\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    233\u001b[0m     nf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sys_data) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk0\n\u001b[1;32m--> 234\u001b[0m     k0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_state_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m k0\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m#warning for if torch fittable?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\deepSI\\fit_systems\\encoders.py:273\u001b[0m, in \u001b[0;36mSS_encoder_general.init_state_multi\u001b[1;34m(self, sys_data, nf, stride)\u001b[0m\n\u001b[0;32m    271\u001b[0m yhist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(yhist,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43muhist\u001b[49m\u001b[43m,\u001b[49m\u001b[43myhist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb)\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20173928\\Miniconda3\\envs\\sindy\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: identity.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# fit_sys = deepSI.fit_systems.SS_encoder_general(nx=2, na=50, nb=50)\n",
    "\n",
    "nx, nu = 2, 1 # state dimension and inputs\n",
    "na, nb = 0, 0\n",
    "\n",
    "f_net = simple_Linear\n",
    "f_net_kwargs= f_net_kwargs={\"feature_library\": poly, \"u\": nu, \"nf\": 10}\n",
    "\n",
    "h_net = identity\n",
    "h_net_kwargs = {}\n",
    "\n",
    "fit_sys = SS_encoder_general_eq(nx=2, na=na, nb=nb, \\\n",
    "                                f_net=f_net, f_net_kwargs=f_net_kwargs,\\\n",
    "                                e_net=identity,\\\n",
    "                                h_net=identity)\n",
    "\n",
    "\n",
    "fit_sys.fit(train, test, epochs=1, batch_size = 2, optimizer_kwargs={\"lr\": 1e-2}, loss_kwargs=dict(nf=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sindy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
